{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfdQDN_B_ksJ"
   },
   "source": [
    "**Data Description:**\n",
    "\n",
    "The Street View House Numbers (SVHN) Dataset SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data formatting but comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNuVDjjo_2cH"
   },
   "source": [
    "## **Importing Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "LKP_FVfRotUE",
    "outputId": "fe1fdf75-0794-4203-bc84-321e5eeddc1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from  google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.optimizers import SGD,RMSprop,Adam,Nadam\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense,Dropout,LSTM\n",
    "from keras.layers import Activation,Flatten,Input,BatchNormalization\n",
    "from keras.layers import Conv1D,MaxPooling1D,Conv2D,MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D,GlobalMaxPooling2D\n",
    "\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FDiTPXxbup8A",
    "outputId": "b4d8f287-5d1c-4ddd-a538-35135c3e9538"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJdbJRibAH_A"
   },
   "source": [
    "## **Loading the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "y5asOIYK5BqS",
    "outputId": "67a9e0f0-fd63-445b-be67-64126b61e556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4-cHSpl5erG"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/gdrive/My Drive/AIML/Great Learning/Neural Networks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byeqhDEBuxQb"
   },
   "outputs": [],
   "source": [
    "filename = 'SVHN_single_grey1.h5'\n",
    "h5f = h5py.File(filename,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqP398gf50jO"
   },
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTfLq88WAPhC"
   },
   "source": [
    "## **Understanding the train/val/test splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sGRJjTb6G0m"
   },
   "outputs": [],
   "source": [
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "X_val = h5f['X_val'][:]\n",
    "y_val = h5f['y_val'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uP6ffpgcUl0n",
    "outputId": "4a6eabaa-2cf5-447a-d4ea-ee0c36395d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method File.close of <HDF5 file \"SVHN_single_grey1.h5\" (mode r)>>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "N0oY6nx_6pUM",
    "outputId": "0fb68ed7-004d-4a9f-ecc9-7efb5380bc5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(42000,)\n",
      "(18000, 32, 32)\n",
      "(18000,)\n",
      "(60000, 32, 32)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "VEzfQyql6yE-",
    "outputId": "e56a9f92-cd38-4967-af50-fc1f6323f710"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  7\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[2000])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_train[2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lyIGi7UOfeuK"
   },
   "source": [
    "## **Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-tkoVQtfbNX"
   },
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 32, 32) => (n, 1024)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_val = X_val.reshape((X_val.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHzxaVTyfqu6"
   },
   "outputs": [],
   "source": [
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gEU-tbMMhjAh",
    "outputId": "3b279c5b-cd49-40eb-ac9e-3968784cb08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (60000, 1024) (18000, 1024) (42000, 10) (60000, 10) (18000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8NPvOMPAmYp"
   },
   "source": [
    "## **Implement and apply a deep neural network classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9qIEVxzmiff"
   },
   "outputs": [],
   "source": [
    "def model_1_train_val(Lambda, hidden_nodes, bsize, steps, opt, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    output_nodes = 10\n",
    "\n",
    "    model_1 = Sequential()\n",
    "\n",
    "    model_1.add(Dense(hidden_nodes, input_shape = (1024, ), activation='relu'))\n",
    "    model_1.add(BatchNormalization())  \n",
    "    model_1.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "    model_1.add(BatchNormalization())  \n",
    "    model_1.add(Dropout(0.25))\n",
    "    model_1.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "    model_1.add(BatchNormalization()) \n",
    "    model_1.add(Dropout(0.25))\n",
    "    model_1.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "    model_1.add(Dropout(0.2))\n",
    "    model_1.add(Dense(output_nodes, kernel_initializer='he_normal', activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))  \n",
    "\n",
    "    # Compile model\n",
    "    model_1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model_1.fit(X_train, y_train,validation_data=(X_val,y_val), batch_size = bsize, epochs = steps, verbose = 1)\n",
    "    model_scores=model_1.evaluate(X_val,y_val,verbose=0)\n",
    "\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "LPtVG223nG8H",
    "outputId": "e8f57d9c-d03e-4ee2-f016-ad8875f67e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 2.1400 - accuracy: 0.2628 - val_loss: 1.5971 - val_accuracy: 0.4444\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 60us/step - loss: 1.4903 - accuracy: 0.4938 - val_loss: 1.3205 - val_accuracy: 0.5647\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 63us/step - loss: 1.3127 - accuracy: 0.5697 - val_loss: 1.4516 - val_accuracy: 0.5114\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 1.2120 - accuracy: 0.6116 - val_loss: 1.2175 - val_accuracy: 0.5999\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.1332 - accuracy: 0.6404 - val_loss: 1.1472 - val_accuracy: 0.6375\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 1.0923 - accuracy: 0.6562 - val_loss: 1.1652 - val_accuracy: 0.6207\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 63us/step - loss: 1.0439 - accuracy: 0.6732 - val_loss: 0.9260 - val_accuracy: 0.7065\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 62us/step - loss: 1.0021 - accuracy: 0.6875 - val_loss: 0.9040 - val_accuracy: 0.7072\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 60us/step - loss: 0.9743 - accuracy: 0.6975 - val_loss: 1.0670 - val_accuracy: 0.6504\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 0.9521 - accuracy: 0.7038 - val_loss: 0.8694 - val_accuracy: 0.7248\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 0.9300 - accuracy: 0.7094 - val_loss: 0.8446 - val_accuracy: 0.7330\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 60us/step - loss: 0.9106 - accuracy: 0.7155 - val_loss: 0.8127 - val_accuracy: 0.7493\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 0.8947 - accuracy: 0.7236 - val_loss: 0.9426 - val_accuracy: 0.6963\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 0.8803 - accuracy: 0.7249 - val_loss: 0.8878 - val_accuracy: 0.7183\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 0.8584 - accuracy: 0.7338 - val_loss: 0.8181 - val_accuracy: 0.7404\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 60us/step - loss: 0.8396 - accuracy: 0.7413 - val_loss: 0.9252 - val_accuracy: 0.7003\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 0.8326 - accuracy: 0.7400 - val_loss: 0.7774 - val_accuracy: 0.7567\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 62us/step - loss: 0.8240 - accuracy: 0.7413 - val_loss: 0.8376 - val_accuracy: 0.7307\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 60us/step - loss: 0.8140 - accuracy: 0.7467 - val_loss: 0.8057 - val_accuracy: 0.7447\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 0.7950 - accuracy: 0.7529 - val_loss: 0.7381 - val_accuracy: 0.7629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7380557815035185, 0.7629333138465881]"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "Lambda = 0\n",
    "hidden_nodes = 100\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "\n",
    "sgd = optimizers.SGD(lr = lr, decay=1e-5, momentum=0.9)\n",
    "sgd1 = optimizers.SGD(lr = lr)\n",
    "sgd_scrore = model_1_train_val(Lambda, hidden_nodes, batch_size, epochs, sgd)\n",
    "sgd_scrore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "TWvJYDzPU9Dr",
    "outputId": "f68d4aca-e49c-40e9-84df-db853c3ef771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 5s 116us/step - loss: 2.1932 - accuracy: 0.2877 - val_loss: 1.8874 - val_accuracy: 0.3646\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 4s 102us/step - loss: 1.2670 - accuracy: 0.5930 - val_loss: 1.6119 - val_accuracy: 0.4631\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 1.0611 - accuracy: 0.6662 - val_loss: 1.2304 - val_accuracy: 0.5986\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 4s 102us/step - loss: 0.9404 - accuracy: 0.7040 - val_loss: 1.0313 - val_accuracy: 0.6687\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 0.8793 - accuracy: 0.7247 - val_loss: 1.1685 - val_accuracy: 0.6053\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 4s 100us/step - loss: 0.8141 - accuracy: 0.7459 - val_loss: 1.0709 - val_accuracy: 0.6468\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 4s 102us/step - loss: 0.7700 - accuracy: 0.7605 - val_loss: 0.9856 - val_accuracy: 0.6793\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 4s 102us/step - loss: 0.7374 - accuracy: 0.7702 - val_loss: 0.9223 - val_accuracy: 0.6930\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 0.7020 - accuracy: 0.7814 - val_loss: 0.8629 - val_accuracy: 0.7199\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 4s 100us/step - loss: 0.6908 - accuracy: 0.7838 - val_loss: 1.1194 - val_accuracy: 0.6413\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 4s 100us/step - loss: 0.6581 - accuracy: 0.7932 - val_loss: 0.9387 - val_accuracy: 0.6907\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 4s 102us/step - loss: 0.6426 - accuracy: 0.7987 - val_loss: 0.8975 - val_accuracy: 0.7168\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 0.6259 - accuracy: 0.8018 - val_loss: 0.8136 - val_accuracy: 0.7339\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 4s 102us/step - loss: 0.6205 - accuracy: 0.8061 - val_loss: 1.0169 - val_accuracy: 0.6599\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 4s 104us/step - loss: 0.5960 - accuracy: 0.8114 - val_loss: 0.8003 - val_accuracy: 0.7377\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 4s 105us/step - loss: 0.5860 - accuracy: 0.8164 - val_loss: 0.9720 - val_accuracy: 0.6932\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 4s 104us/step - loss: 0.5749 - accuracy: 0.8193 - val_loss: 1.0831 - val_accuracy: 0.6534\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 0.5604 - accuracy: 0.8231 - val_loss: 0.6444 - val_accuracy: 0.7947\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 4s 102us/step - loss: 0.5546 - accuracy: 0.8237 - val_loss: 0.7650 - val_accuracy: 0.7541\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 0.5388 - accuracy: 0.8292 - val_loss: 0.5896 - val_accuracy: 0.8126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.589559827530384, 0.812583327293396]"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 0\n",
    "hidden_nodes = 250\n",
    "batch_size = 500\n",
    "epochs = 20\n",
    "\n",
    "adam = optimizers.Adam(lr = lr)\n",
    "\n",
    "adam_scrore = model_1_train_val(Lambda, hidden_nodes, batch_size, epochs, adam)\n",
    "adam_scrore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WdiMM-F7x6-A",
    "outputId": "431a42cc-b30e-4d0d-c94a-1bb5dd62be4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 13s 303us/step - loss: 2.2706 - accuracy: 0.2797 - val_loss: 2.0585 - val_accuracy: 0.3390\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 12s 285us/step - loss: 1.3320 - accuracy: 0.5583 - val_loss: 1.8338 - val_accuracy: 0.3879\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 1.1054 - accuracy: 0.6510 - val_loss: 1.4583 - val_accuracy: 0.5696\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 1.0310 - accuracy: 0.6786 - val_loss: 1.5167 - val_accuracy: 0.5170\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 12s 286us/step - loss: 0.9534 - accuracy: 0.7030 - val_loss: 1.2952 - val_accuracy: 0.5977\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 12s 287us/step - loss: 0.8978 - accuracy: 0.7210 - val_loss: 1.3101 - val_accuracy: 0.5790\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.8521 - accuracy: 0.7327 - val_loss: 1.1210 - val_accuracy: 0.6409\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 12s 286us/step - loss: 0.8239 - accuracy: 0.7435 - val_loss: 0.9279 - val_accuracy: 0.7028\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.7912 - accuracy: 0.7530 - val_loss: 0.9121 - val_accuracy: 0.7141\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.7681 - accuracy: 0.7613 - val_loss: 0.9677 - val_accuracy: 0.6880\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.7510 - accuracy: 0.7649 - val_loss: 0.9060 - val_accuracy: 0.7163\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.7310 - accuracy: 0.7745 - val_loss: 1.1183 - val_accuracy: 0.6461\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.7172 - accuracy: 0.7761 - val_loss: 0.7348 - val_accuracy: 0.7685\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.7064 - accuracy: 0.7813 - val_loss: 1.2432 - val_accuracy: 0.6294\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 12s 287us/step - loss: 0.6862 - accuracy: 0.7858 - val_loss: 1.0785 - val_accuracy: 0.6704\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 12s 285us/step - loss: 0.6736 - accuracy: 0.7915 - val_loss: 0.9848 - val_accuracy: 0.7266\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 13s 316us/step - loss: 0.6671 - accuracy: 0.7935 - val_loss: 0.8476 - val_accuracy: 0.7495\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.6644 - accuracy: 0.7945 - val_loss: 1.0073 - val_accuracy: 0.6876\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.6522 - accuracy: 0.7963 - val_loss: 0.7898 - val_accuracy: 0.7539\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 12s 286us/step - loss: 0.6251 - accuracy: 0.8067 - val_loss: 0.7428 - val_accuracy: 0.7662\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 12s 287us/step - loss: 0.6289 - accuracy: 0.8061 - val_loss: 0.8103 - val_accuracy: 0.7466\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 12s 287us/step - loss: 0.6237 - accuracy: 0.8080 - val_loss: 0.8993 - val_accuracy: 0.7201\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 12s 287us/step - loss: 0.6355 - accuracy: 0.8043 - val_loss: 0.8667 - val_accuracy: 0.7320\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.6193 - accuracy: 0.8081 - val_loss: 0.6592 - val_accuracy: 0.7928\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.6045 - accuracy: 0.8129 - val_loss: 0.9281 - val_accuracy: 0.7164\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 12s 296us/step - loss: 0.6093 - accuracy: 0.8117 - val_loss: 1.0752 - val_accuracy: 0.6767\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.6034 - accuracy: 0.8137 - val_loss: 0.6633 - val_accuracy: 0.7968\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.5963 - accuracy: 0.8158 - val_loss: 0.7683 - val_accuracy: 0.7628\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.5939 - accuracy: 0.8162 - val_loss: 0.8684 - val_accuracy: 0.7401\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 12s 294us/step - loss: 0.5864 - accuracy: 0.8174 - val_loss: 0.8857 - val_accuracy: 0.7250\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.5793 - accuracy: 0.8226 - val_loss: 0.7114 - val_accuracy: 0.7762\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.5719 - accuracy: 0.8232 - val_loss: 0.6226 - val_accuracy: 0.8092\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.5766 - accuracy: 0.8214 - val_loss: 0.7137 - val_accuracy: 0.7811\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.5728 - accuracy: 0.8246 - val_loss: 0.6684 - val_accuracy: 0.7949\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.5615 - accuracy: 0.8286 - val_loss: 0.6079 - val_accuracy: 0.8075\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.5637 - accuracy: 0.8257 - val_loss: 0.6909 - val_accuracy: 0.7820\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.5615 - accuracy: 0.8268 - val_loss: 0.7693 - val_accuracy: 0.7635\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.5562 - accuracy: 0.8285 - val_loss: 0.8319 - val_accuracy: 0.7340\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.5525 - accuracy: 0.8290 - val_loss: 0.5518 - val_accuracy: 0.8304\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.5447 - accuracy: 0.8314 - val_loss: 0.6503 - val_accuracy: 0.8056\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.5416 - accuracy: 0.8330 - val_loss: 0.7326 - val_accuracy: 0.7850\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.5409 - accuracy: 0.8337 - val_loss: 0.6166 - val_accuracy: 0.8150\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.5404 - accuracy: 0.8353 - val_loss: 0.6599 - val_accuracy: 0.7987\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 12s 286us/step - loss: 0.5320 - accuracy: 0.8363 - val_loss: 0.6392 - val_accuracy: 0.8037\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 12s 287us/step - loss: 0.5324 - accuracy: 0.8371 - val_loss: 0.6882 - val_accuracy: 0.7947\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.5238 - accuracy: 0.8416 - val_loss: 0.6329 - val_accuracy: 0.8097\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 12s 285us/step - loss: 0.5152 - accuracy: 0.8396 - val_loss: 0.9239 - val_accuracy: 0.7445\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 12s 286us/step - loss: 0.5252 - accuracy: 0.8367 - val_loss: 0.6416 - val_accuracy: 0.8049\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.5148 - accuracy: 0.8422 - val_loss: 0.5804 - val_accuracy: 0.8255\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 12s 288us/step - loss: 0.5157 - accuracy: 0.8426 - val_loss: 0.5085 - val_accuracy: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5084821804533403, 0.8433166742324829]"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "Lambda = 0\n",
    "hidden_nodes = 512\n",
    "batch_size = 200\n",
    "epochs = 50\n",
    "\n",
    "adam = optimizers.Adam(lr = lr)\n",
    "\n",
    "adam_scrore = model_1_train_val(Lambda, hidden_nodes, batch_size, epochs, adam)\n",
    "adam_scrore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipaJvxsFBPh5"
   },
   "source": [
    "### **Writing a generalized function which can be called over a loop for various combination of Learning rate and Lambda value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mumfDYV-pZPj"
   },
   "outputs": [],
   "source": [
    "def model_2_train_val(iterations, Lambda, hidden_nodes, bsize, steps, opt, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    output_nodes = 10\n",
    "    iterations = iterations\n",
    "\n",
    "    model_1 = Sequential()\n",
    "\n",
    "    model_1.add(Dense(hidden_nodes, input_shape = (1024, ), activation='relu'))\n",
    "    model_1.add(BatchNormalization())  \n",
    "    model_1.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "    model_1.add(BatchNormalization())  \n",
    "    model_1.add(Dropout(0.25))\n",
    "    model_1.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "    model_1.add(BatchNormalization()) \n",
    "    model_1.add(Dropout(0.25))\n",
    "    model_1.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "    model_1.add(Dropout(0.2))\n",
    "    model_1.add(Dense(output_nodes, kernel_initializer='he_normal', activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))  \n",
    "\n",
    "    # Compile model\n",
    "    model_1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model_1.fit(X_train, y_train,validation_data=(X_val,y_val), batch_size = bsize, epochs = steps, verbose = 1)\n",
    "    model_scores=model_1.evaluate(X_val,y_val,verbose=0)\n",
    "\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Je2urJ3DoZwc"
   },
   "outputs": [],
   "source": [
    "#random configuration values\n",
    "hidden_nodes = 200\n",
    "batch_size = 1000\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OmLIr5slqjXs",
    "outputId": "eae927e6-7184-4873-8375-af195a060949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 2.5800 - accuracy: 0.1870 - val_loss: 2.7340 - val_accuracy: 0.1887\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.6824 - accuracy: 0.4345 - val_loss: 1.7879 - val_accuracy: 0.4190\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 1.3038 - accuracy: 0.5799 - val_loss: 1.6199 - val_accuracy: 0.4635\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.1583 - accuracy: 0.6365 - val_loss: 1.2756 - val_accuracy: 0.5893\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.0516 - accuracy: 0.6745 - val_loss: 1.1005 - val_accuracy: 0.6532\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.9875 - accuracy: 0.6939 - val_loss: 1.0304 - val_accuracy: 0.6733\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.9279 - accuracy: 0.7139 - val_loss: 0.9666 - val_accuracy: 0.7043\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.8761 - accuracy: 0.7313 - val_loss: 0.9373 - val_accuracy: 0.7049\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.8468 - accuracy: 0.7401 - val_loss: 1.0428 - val_accuracy: 0.6700\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.8190 - accuracy: 0.7490 - val_loss: 1.0061 - val_accuracy: 0.6874\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.7877 - accuracy: 0.7586 - val_loss: 0.9289 - val_accuracy: 0.7037\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.7575 - accuracy: 0.7673 - val_loss: 0.9287 - val_accuracy: 0.7046\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.7397 - accuracy: 0.7717 - val_loss: 0.7890 - val_accuracy: 0.7489\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.7144 - accuracy: 0.7817 - val_loss: 1.0125 - val_accuracy: 0.6659\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.6926 - accuracy: 0.7862 - val_loss: 0.6920 - val_accuracy: 0.7871\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.6752 - accuracy: 0.7910 - val_loss: 0.8862 - val_accuracy: 0.7131\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6719 - accuracy: 0.7932 - val_loss: 0.7929 - val_accuracy: 0.7555\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6480 - accuracy: 0.8013 - val_loss: 0.9360 - val_accuracy: 0.7016\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.6438 - accuracy: 0.8009 - val_loss: 0.7512 - val_accuracy: 0.7621\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6234 - accuracy: 0.8074 - val_loss: 0.6494 - val_accuracy: 0.7956\n",
      "Try 1/5: Best_val_acc: [0.6493658990740776, 0.7955833077430725], lr: 0.0007668630001688477, Lambda: 0.0009907294593495255\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 4.4796 - accuracy: 0.0967 - val_loss: 141.9381 - val_accuracy: 0.1013\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.4475 - accuracy: 0.0979 - val_loss: 2.5750 - val_accuracy: 0.0994\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 2.3231 - accuracy: 0.1004 - val_loss: 2.3133 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3082 - accuracy: 0.0991 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.3044 - accuracy: 0.1044 - val_loss: 2.3050 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3043 - accuracy: 0.0992 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 2.3034 - accuracy: 0.0983 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.3038 - accuracy: 0.0998 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.3041 - accuracy: 0.0985 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.3042 - accuracy: 0.0968 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3035 - accuracy: 0.1007 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3043 - accuracy: 0.1020 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.3042 - accuracy: 0.0974 - val_loss: 2.3052 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.3042 - accuracy: 0.0998 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3043 - accuracy: 0.0995 - val_loss: 2.3052 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.3041 - accuracy: 0.1004 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3044 - accuracy: 0.0996 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 2.3044 - accuracy: 0.0980 - val_loss: 2.3060 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.3048 - accuracy: 0.0970 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 2.3039 - accuracy: 0.0990 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Try 2/5: Best_val_acc: [2.303433819325765, 0.10001666843891144], lr: 0.09815913613534363, Lambda: 0.007608199878796004\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 2.1208 - accuracy: 0.2713 - val_loss: 2.8269 - val_accuracy: 0.1928\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 1.3929 - accuracy: 0.5334 - val_loss: 2.2558 - val_accuracy: 0.3422\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 1.1613 - accuracy: 0.6322 - val_loss: 1.6931 - val_accuracy: 0.4661\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.0487 - accuracy: 0.6717 - val_loss: 1.2851 - val_accuracy: 0.6064\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.9645 - accuracy: 0.7006 - val_loss: 1.3953 - val_accuracy: 0.5366\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.9011 - accuracy: 0.7194 - val_loss: 1.7490 - val_accuracy: 0.4565\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.8440 - accuracy: 0.7376 - val_loss: 1.1921 - val_accuracy: 0.5926\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.8135 - accuracy: 0.7480 - val_loss: 1.8408 - val_accuracy: 0.4197\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.7752 - accuracy: 0.7605 - val_loss: 1.5002 - val_accuracy: 0.5770\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.7490 - accuracy: 0.7685 - val_loss: 0.9856 - val_accuracy: 0.6854\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.7151 - accuracy: 0.7787 - val_loss: 1.1860 - val_accuracy: 0.6253\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.7042 - accuracy: 0.7822 - val_loss: 0.9512 - val_accuracy: 0.6968\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6727 - accuracy: 0.7951 - val_loss: 1.1759 - val_accuracy: 0.6383\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.6700 - accuracy: 0.7927 - val_loss: 0.9813 - val_accuracy: 0.6873\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.6478 - accuracy: 0.8024 - val_loss: 0.9905 - val_accuracy: 0.6874\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6237 - accuracy: 0.8088 - val_loss: 0.7369 - val_accuracy: 0.7659\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.6193 - accuracy: 0.8092 - val_loss: 1.1120 - val_accuracy: 0.6469\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6018 - accuracy: 0.8142 - val_loss: 1.1526 - val_accuracy: 0.6586\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6038 - accuracy: 0.8137 - val_loss: 0.8241 - val_accuracy: 0.7366\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.5940 - accuracy: 0.8176 - val_loss: 1.0255 - val_accuracy: 0.6702\n",
      "Try 3/5: Best_val_acc: [1.0255500108480453, 0.670199990272522], lr: 0.008299639806081244, Lambda: 0.0020466694472055583\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 2.1549 - accuracy: 0.2707 - val_loss: 2.1387 - val_accuracy: 0.2569\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.2985 - accuracy: 0.5724 - val_loss: 1.7037 - val_accuracy: 0.4143\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.1032 - accuracy: 0.6493 - val_loss: 2.1250 - val_accuracy: 0.3821\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.9871 - accuracy: 0.6891 - val_loss: 1.4324 - val_accuracy: 0.5192\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9254 - accuracy: 0.7092 - val_loss: 1.2467 - val_accuracy: 0.5964\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.8675 - accuracy: 0.7266 - val_loss: 1.3465 - val_accuracy: 0.5587\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.8309 - accuracy: 0.7386 - val_loss: 1.1417 - val_accuracy: 0.6281\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.8143 - accuracy: 0.7420 - val_loss: 1.7760 - val_accuracy: 0.4396\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.7718 - accuracy: 0.7580 - val_loss: 1.3137 - val_accuracy: 0.5617\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.7322 - accuracy: 0.7706 - val_loss: 0.8787 - val_accuracy: 0.7189\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.7158 - accuracy: 0.7747 - val_loss: 1.0000 - val_accuracy: 0.6676\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6850 - accuracy: 0.7866 - val_loss: 1.0035 - val_accuracy: 0.6790\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.6655 - accuracy: 0.7931 - val_loss: 0.9973 - val_accuracy: 0.6787\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.6523 - accuracy: 0.7935 - val_loss: 1.3432 - val_accuracy: 0.5873\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6382 - accuracy: 0.8000 - val_loss: 0.9638 - val_accuracy: 0.6834\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6151 - accuracy: 0.8058 - val_loss: 1.2634 - val_accuracy: 0.6045\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6086 - accuracy: 0.8081 - val_loss: 0.8969 - val_accuracy: 0.7191\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6010 - accuracy: 0.8117 - val_loss: 1.0417 - val_accuracy: 0.6730\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.5782 - accuracy: 0.8194 - val_loss: 0.6819 - val_accuracy: 0.7803\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.5655 - accuracy: 0.8223 - val_loss: 0.7197 - val_accuracy: 0.7771\n",
      "Try 4/5: Best_val_acc: [0.7196861855943998, 0.7771333456039429], lr: 0.005554524538388575, Lambda: 0.0001816703238621585\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 2.1496 - accuracy: 0.2857 - val_loss: 2.0092 - val_accuracy: 0.2930\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.3245 - accuracy: 0.5690 - val_loss: 1.4668 - val_accuracy: 0.5131\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.1100 - accuracy: 0.6507 - val_loss: 1.3526 - val_accuracy: 0.5347\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.0165 - accuracy: 0.6804 - val_loss: 1.4142 - val_accuracy: 0.5214\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9317 - accuracy: 0.7080 - val_loss: 1.0969 - val_accuracy: 0.6363\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8837 - accuracy: 0.7202 - val_loss: 1.1009 - val_accuracy: 0.6324\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8312 - accuracy: 0.7390 - val_loss: 1.1917 - val_accuracy: 0.6179\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.7799 - accuracy: 0.7565 - val_loss: 1.3224 - val_accuracy: 0.5638\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.7490 - accuracy: 0.7647 - val_loss: 1.9187 - val_accuracy: 0.4568\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.7094 - accuracy: 0.7788 - val_loss: 1.0681 - val_accuracy: 0.6533\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.6939 - accuracy: 0.7828 - val_loss: 1.3748 - val_accuracy: 0.5615\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.6700 - accuracy: 0.7909 - val_loss: 1.0544 - val_accuracy: 0.6541\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.6569 - accuracy: 0.7927 - val_loss: 1.1172 - val_accuracy: 0.6172\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.6389 - accuracy: 0.7992 - val_loss: 0.7680 - val_accuracy: 0.7545\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.6231 - accuracy: 0.8040 - val_loss: 0.9469 - val_accuracy: 0.6931\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.6032 - accuracy: 0.8105 - val_loss: 0.8548 - val_accuracy: 0.7232\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.5889 - accuracy: 0.8153 - val_loss: 0.9943 - val_accuracy: 0.6904\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.5917 - accuracy: 0.8138 - val_loss: 0.9172 - val_accuracy: 0.7060\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.5677 - accuracy: 0.8212 - val_loss: 0.6792 - val_accuracy: 0.7829\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.5537 - accuracy: 0.8270 - val_loss: 0.9371 - val_accuracy: 0.6979\n",
      "Try 5/5: Best_val_acc: [0.9371239026546478, 0.6979333162307739], lr: 0.0031335967614980506, Lambda: 0.00017408945937082623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling the function over a loop to indentify the best hypertuning parameters for ADAM optimizer\n",
    "import math\n",
    "for k in range(1,6):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
    "    adam = optimizers.Adam(lr = lr)\n",
    "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
    "    best_acc = model_2_train_val(5, Lambda, hidden_nodes, batch_size, epochs, adam, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 5, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xiCn1qQJrT_q",
    "outputId": "21b16f9b-a751-4468-8c94-d0ce2d73a85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 3.2519 - accuracy: 0.0989 - val_loss: 3.5817 - val_accuracy: 0.1110\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 3.1182 - accuracy: 0.1063 - val_loss: 2.7138 - val_accuracy: 0.1216\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 3.0025 - accuracy: 0.1120 - val_loss: 2.6267 - val_accuracy: 0.1247\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 2.9351 - accuracy: 0.1192 - val_loss: 2.6230 - val_accuracy: 0.1218\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.8943 - accuracy: 0.1255 - val_loss: 2.4559 - val_accuracy: 0.1444\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.8531 - accuracy: 0.1286 - val_loss: 2.4047 - val_accuracy: 0.1577\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 2.8085 - accuracy: 0.1350 - val_loss: 2.3485 - val_accuracy: 0.1731\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.7713 - accuracy: 0.1422 - val_loss: 2.3083 - val_accuracy: 0.1895\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.7315 - accuracy: 0.1459 - val_loss: 2.3149 - val_accuracy: 0.2029\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 65us/step - loss: 2.6913 - accuracy: 0.1512 - val_loss: 2.2521 - val_accuracy: 0.2146\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 2.6610 - accuracy: 0.1590 - val_loss: 2.2012 - val_accuracy: 0.2316\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 2.6199 - accuracy: 0.1640 - val_loss: 2.2052 - val_accuracy: 0.2335\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 2.5903 - accuracy: 0.1706 - val_loss: 2.1422 - val_accuracy: 0.2582\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.5505 - accuracy: 0.1777 - val_loss: 2.1248 - val_accuracy: 0.2646\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.5234 - accuracy: 0.1828 - val_loss: 2.0886 - val_accuracy: 0.2844\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.4982 - accuracy: 0.1935 - val_loss: 2.0441 - val_accuracy: 0.3007\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.4613 - accuracy: 0.2009 - val_loss: 2.0248 - val_accuracy: 0.3094\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.4285 - accuracy: 0.2105 - val_loss: 2.0858 - val_accuracy: 0.2982\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 2.4072 - accuracy: 0.2121 - val_loss: 2.0023 - val_accuracy: 0.3252\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.3837 - accuracy: 0.2217 - val_loss: 1.9477 - val_accuracy: 0.3417\n",
      "Try 1/5: Best_val_acc: [1.947737014579773, 0.3417166769504547], lr: 0.00018164961485986456, Lambda: 0.0008252754556136713\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 3.1053 - accuracy: 0.1100 - val_loss: 4.5958 - val_accuracy: 0.1037\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 65us/step - loss: 2.8145 - accuracy: 0.1321 - val_loss: 2.9605 - val_accuracy: 0.1345\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 65us/step - loss: 2.6218 - accuracy: 0.1640 - val_loss: 2.6595 - val_accuracy: 0.1623\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 65us/step - loss: 2.4643 - accuracy: 0.1979 - val_loss: 2.1629 - val_accuracy: 0.2614\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 2.3108 - accuracy: 0.2324 - val_loss: 2.0159 - val_accuracy: 0.3097\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.1751 - accuracy: 0.2718 - val_loss: 1.8415 - val_accuracy: 0.3782\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 2.0584 - accuracy: 0.3072 - val_loss: 1.7207 - val_accuracy: 0.4213\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.9491 - accuracy: 0.3404 - val_loss: 1.6290 - val_accuracy: 0.4679\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 1.8610 - accuracy: 0.3701 - val_loss: 1.5232 - val_accuracy: 0.5051\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.7831 - accuracy: 0.3961 - val_loss: 1.4859 - val_accuracy: 0.5188\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.7145 - accuracy: 0.4200 - val_loss: 1.4053 - val_accuracy: 0.5490\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.6600 - accuracy: 0.4420 - val_loss: 1.3776 - val_accuracy: 0.5561\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.6013 - accuracy: 0.4630 - val_loss: 1.2884 - val_accuracy: 0.5986\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 1.5543 - accuracy: 0.4832 - val_loss: 1.2731 - val_accuracy: 0.5988\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.5098 - accuracy: 0.5007 - val_loss: 1.2263 - val_accuracy: 0.6249\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.4637 - accuracy: 0.5181 - val_loss: 1.1839 - val_accuracy: 0.6401\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.4282 - accuracy: 0.5268 - val_loss: 1.1785 - val_accuracy: 0.6321\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 1.4042 - accuracy: 0.5414 - val_loss: 1.1419 - val_accuracy: 0.6488\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.3699 - accuracy: 0.5546 - val_loss: 1.1118 - val_accuracy: 0.6640\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 77us/step - loss: 1.3468 - accuracy: 0.5623 - val_loss: 1.1038 - val_accuracy: 0.6645\n",
      "Try 2/5: Best_val_acc: [1.1038389315605164, 0.6645166873931885], lr: 0.0010213702817878868, Lambda: 0.0015128330422674498\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 2.9347 - accuracy: 0.1199 - val_loss: 3.3779 - val_accuracy: 0.1282\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.4689 - accuracy: 0.1848 - val_loss: 2.5892 - val_accuracy: 0.1802\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 2.1054 - accuracy: 0.2792 - val_loss: 1.9073 - val_accuracy: 0.3313\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 5s 117us/step - loss: 1.8248 - accuracy: 0.3716 - val_loss: 1.6524 - val_accuracy: 0.4411\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 1.6433 - accuracy: 0.4365 - val_loss: 1.4166 - val_accuracy: 0.5443\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.5156 - accuracy: 0.4904 - val_loss: 1.3159 - val_accuracy: 0.5718\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.4078 - accuracy: 0.5335 - val_loss: 1.2177 - val_accuracy: 0.6105\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.3377 - accuracy: 0.5636 - val_loss: 1.1744 - val_accuracy: 0.6254\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.2766 - accuracy: 0.5835 - val_loss: 1.0947 - val_accuracy: 0.6605\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.2343 - accuracy: 0.5995 - val_loss: 1.0785 - val_accuracy: 0.6569\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.1845 - accuracy: 0.6181 - val_loss: 1.0659 - val_accuracy: 0.6669\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.1556 - accuracy: 0.6322 - val_loss: 0.9992 - val_accuracy: 0.6891\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.1227 - accuracy: 0.6418 - val_loss: 0.9632 - val_accuracy: 0.6963\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.1026 - accuracy: 0.6507 - val_loss: 0.9427 - val_accuracy: 0.7053\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.0678 - accuracy: 0.6605 - val_loss: 0.9012 - val_accuracy: 0.7225\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.0512 - accuracy: 0.6658 - val_loss: 0.9050 - val_accuracy: 0.7196\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.0356 - accuracy: 0.6745 - val_loss: 0.9163 - val_accuracy: 0.7125\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.0179 - accuracy: 0.6794 - val_loss: 0.8708 - val_accuracy: 0.7314\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9993 - accuracy: 0.6867 - val_loss: 0.8710 - val_accuracy: 0.7301\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9776 - accuracy: 0.6912 - val_loss: 0.8640 - val_accuracy: 0.7366\n",
      "Try 3/5: Best_val_acc: [0.8640309031089147, 0.7365666627883911], lr: 0.0033214989603793047, Lambda: 0.00010655851380494444\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 3.2516 - accuracy: 0.1059 - val_loss: 4.1025 - val_accuracy: 0.1014\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.9869 - accuracy: 0.1137 - val_loss: 2.9874 - val_accuracy: 0.1124\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.8665 - accuracy: 0.1296 - val_loss: 2.5250 - val_accuracy: 0.1394\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.7827 - accuracy: 0.1386 - val_loss: 2.4859 - val_accuracy: 0.1468\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.6879 - accuracy: 0.1552 - val_loss: 2.4014 - val_accuracy: 0.1797\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.6236 - accuracy: 0.1647 - val_loss: 2.3515 - val_accuracy: 0.1901\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.5431 - accuracy: 0.1829 - val_loss: 2.1854 - val_accuracy: 0.2497\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.4589 - accuracy: 0.2008 - val_loss: 2.1048 - val_accuracy: 0.2891\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.4017 - accuracy: 0.2159 - val_loss: 2.0328 - val_accuracy: 0.3134\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3244 - accuracy: 0.2358 - val_loss: 1.9485 - val_accuracy: 0.3456\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.2708 - accuracy: 0.2509 - val_loss: 1.8752 - val_accuracy: 0.3866\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.2002 - accuracy: 0.2676 - val_loss: 1.8260 - val_accuracy: 0.4126\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.1411 - accuracy: 0.2884 - val_loss: 1.7529 - val_accuracy: 0.4438\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.0809 - accuracy: 0.3029 - val_loss: 1.6931 - val_accuracy: 0.4664\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.0236 - accuracy: 0.3258 - val_loss: 1.6610 - val_accuracy: 0.4825\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.9804 - accuracy: 0.3370 - val_loss: 1.6094 - val_accuracy: 0.4990\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.9324 - accuracy: 0.3539 - val_loss: 1.5833 - val_accuracy: 0.5096\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.8948 - accuracy: 0.3688 - val_loss: 1.5267 - val_accuracy: 0.5337\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.8486 - accuracy: 0.3814 - val_loss: 1.4958 - val_accuracy: 0.5449\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.8196 - accuracy: 0.3936 - val_loss: 1.4636 - val_accuracy: 0.5502\n",
      "Try 4/5: Best_val_acc: [1.4636351425011953, 0.550166666507721], lr: 0.0004813543241444311, Lambda: 0.002810260348944993\n",
      "\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 3.4728 - accuracy: 0.1073 - val_loss: 4.0805 - val_accuracy: 0.1116\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 3.1872 - accuracy: 0.1174 - val_loss: 2.8718 - val_accuracy: 0.1244\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 3.0676 - accuracy: 0.1205 - val_loss: 2.6864 - val_accuracy: 0.1276\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.9907 - accuracy: 0.1260 - val_loss: 2.6436 - val_accuracy: 0.1460\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.9373 - accuracy: 0.1286 - val_loss: 2.5084 - val_accuracy: 0.1622\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.8799 - accuracy: 0.1362 - val_loss: 2.4528 - val_accuracy: 0.1783\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.8421 - accuracy: 0.1444 - val_loss: 2.3939 - val_accuracy: 0.1878\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.8009 - accuracy: 0.1497 - val_loss: 2.4327 - val_accuracy: 0.1981\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.7707 - accuracy: 0.1517 - val_loss: 2.3235 - val_accuracy: 0.2181\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.7315 - accuracy: 0.1612 - val_loss: 2.3114 - val_accuracy: 0.2315\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.6898 - accuracy: 0.1678 - val_loss: 2.2561 - val_accuracy: 0.2515\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.6566 - accuracy: 0.1779 - val_loss: 2.2742 - val_accuracy: 0.2665\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.6173 - accuracy: 0.1861 - val_loss: 2.1904 - val_accuracy: 0.2810\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.5889 - accuracy: 0.1890 - val_loss: 2.2071 - val_accuracy: 0.2740\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.5416 - accuracy: 0.1994 - val_loss: 2.1313 - val_accuracy: 0.3050\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 2.5196 - accuracy: 0.2082 - val_loss: 2.1058 - val_accuracy: 0.3218\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 2.4774 - accuracy: 0.2154 - val_loss: 2.0657 - val_accuracy: 0.3349\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 2.4516 - accuracy: 0.2246 - val_loss: 2.0334 - val_accuracy: 0.3488\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.4006 - accuracy: 0.2371 - val_loss: 2.0173 - val_accuracy: 0.3584\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.3748 - accuracy: 0.2410 - val_loss: 1.9739 - val_accuracy: 0.3773\n",
      "Try 5/5: Best_val_acc: [1.9738508587519328, 0.3773166537284851], lr: 0.0002147681309794443, Lambda: 0.005878690692339748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling the function over a loop to indentify the best hypertuning parameters for SGD optimizer\n",
    "\n",
    "hidden_nodes = 200\n",
    "batch_size = 1000\n",
    "epochs = 20\n",
    "\n",
    "for k in range(1,6):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
    "    sgd = optimizers.SGD(lr = lr, decay=1e-5, momentum=0.9)\n",
    "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
    "    best_acc = model_2_train_val(5, Lambda, hidden_nodes, batch_size, epochs, sgd, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 5, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OiB-jNYa34Bk",
    "outputId": "fa90af4b-f3eb-4883-cc10-35058aaa50e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 2.9584 - accuracy: 0.1226 - val_loss: 4.3623 - val_accuracy: 0.1084\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 2.4545 - accuracy: 0.1870 - val_loss: 2.3000 - val_accuracy: 0.2115\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 2.1002 - accuracy: 0.2843 - val_loss: 1.7851 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.8506 - accuracy: 0.3627 - val_loss: 1.5683 - val_accuracy: 0.4949\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.6601 - accuracy: 0.4335 - val_loss: 1.3855 - val_accuracy: 0.5621\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.5263 - accuracy: 0.4855 - val_loss: 1.3541 - val_accuracy: 0.5726\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.4306 - accuracy: 0.5248 - val_loss: 1.2380 - val_accuracy: 0.6164\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.3476 - accuracy: 0.5582 - val_loss: 1.1049 - val_accuracy: 0.6636\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.2895 - accuracy: 0.5802 - val_loss: 1.0911 - val_accuracy: 0.6532\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.2329 - accuracy: 0.6018 - val_loss: 1.0587 - val_accuracy: 0.6702\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.1954 - accuracy: 0.6155 - val_loss: 1.0120 - val_accuracy: 0.6873\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.1595 - accuracy: 0.6296 - val_loss: 0.9930 - val_accuracy: 0.6860\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.1345 - accuracy: 0.6385 - val_loss: 0.9486 - val_accuracy: 0.7056\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 1.1050 - accuracy: 0.6499 - val_loss: 0.9715 - val_accuracy: 0.6928\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 1.0895 - accuracy: 0.6542 - val_loss: 0.9248 - val_accuracy: 0.7128\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.0625 - accuracy: 0.6623 - val_loss: 0.9622 - val_accuracy: 0.6959\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.0387 - accuracy: 0.6715 - val_loss: 0.8925 - val_accuracy: 0.7202\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.0219 - accuracy: 0.6780 - val_loss: 0.9025 - val_accuracy: 0.7158\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 1.0072 - accuracy: 0.6834 - val_loss: 0.8645 - val_accuracy: 0.7313\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9882 - accuracy: 0.6868 - val_loss: 0.8594 - val_accuracy: 0.7378\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9822 - accuracy: 0.6953 - val_loss: 0.8194 - val_accuracy: 0.7466\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9647 - accuracy: 0.6956 - val_loss: 0.8487 - val_accuracy: 0.7321\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9431 - accuracy: 0.7025 - val_loss: 0.8820 - val_accuracy: 0.7201\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.9283 - accuracy: 0.7072 - val_loss: 0.7804 - val_accuracy: 0.7597\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.9301 - accuracy: 0.7100 - val_loss: 0.8547 - val_accuracy: 0.7270\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.9114 - accuracy: 0.7132 - val_loss: 0.7666 - val_accuracy: 0.7623\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8984 - accuracy: 0.7185 - val_loss: 0.7931 - val_accuracy: 0.7538\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.8923 - accuracy: 0.7223 - val_loss: 0.7877 - val_accuracy: 0.7556\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8788 - accuracy: 0.7236 - val_loss: 0.7374 - val_accuracy: 0.7724\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.8725 - accuracy: 0.7268 - val_loss: 0.7591 - val_accuracy: 0.7633\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8625 - accuracy: 0.7280 - val_loss: 0.7341 - val_accuracy: 0.7709\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8558 - accuracy: 0.7319 - val_loss: 0.7437 - val_accuracy: 0.7694\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.8422 - accuracy: 0.7378 - val_loss: 0.7263 - val_accuracy: 0.7751\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.8396 - accuracy: 0.7370 - val_loss: 0.7643 - val_accuracy: 0.7611\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.8296 - accuracy: 0.7415 - val_loss: 0.7274 - val_accuracy: 0.7768\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8223 - accuracy: 0.7431 - val_loss: 0.7177 - val_accuracy: 0.7800\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.8126 - accuracy: 0.7460 - val_loss: 0.7280 - val_accuracy: 0.7742\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.8022 - accuracy: 0.7501 - val_loss: 0.7100 - val_accuracy: 0.7781\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.8022 - accuracy: 0.7470 - val_loss: 0.6951 - val_accuracy: 0.7834\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.7884 - accuracy: 0.7535 - val_loss: 0.6873 - val_accuracy: 0.7875\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.7865 - accuracy: 0.7540 - val_loss: 0.6723 - val_accuracy: 0.7891\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.7825 - accuracy: 0.7555 - val_loss: 0.6993 - val_accuracy: 0.7818\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.7684 - accuracy: 0.7607 - val_loss: 0.6938 - val_accuracy: 0.7815\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.7677 - accuracy: 0.7603 - val_loss: 0.6542 - val_accuracy: 0.7987\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.7658 - accuracy: 0.7594 - val_loss: 0.6841 - val_accuracy: 0.7935\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.7619 - accuracy: 0.7604 - val_loss: 0.6328 - val_accuracy: 0.8052\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.7593 - accuracy: 0.7637 - val_loss: 0.7317 - val_accuracy: 0.7662\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.7514 - accuracy: 0.7635 - val_loss: 0.6569 - val_accuracy: 0.7974\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.7411 - accuracy: 0.7691 - val_loss: 0.6468 - val_accuracy: 0.7983\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 0.7402 - accuracy: 0.7694 - val_loss: 0.7005 - val_accuracy: 0.7814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.700470710404714, 0.7813666462898254]"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0033214989603793047\n",
    "Lambda = 0.00010655851380494444\n",
    "hidden_nodes = 200\n",
    "batch_size = 1000\n",
    "epochs = 50\n",
    "\n",
    "sgd = optimizers.SGD(lr = lr, decay=1e-5, momentum=0.9)\n",
    "\n",
    "sgd_scrore_tuned = model_2_train_val(1, Lambda, hidden_nodes, batch_size, epochs, sgd)\n",
    "sgd_scrore_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "w3ITprmh5Lm5",
    "outputId": "5716f257-9ac7-47ff-ff63-0eaa0fa666a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 2.5559 - accuracy: 0.1925 - val_loss: 2.4897 - val_accuracy: 0.2354\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 1.6573 - accuracy: 0.4460 - val_loss: 1.6955 - val_accuracy: 0.4418\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.2965 - accuracy: 0.5862 - val_loss: 1.3361 - val_accuracy: 0.5745\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 1.1461 - accuracy: 0.6424 - val_loss: 1.2161 - val_accuracy: 0.6069\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.0533 - accuracy: 0.6735 - val_loss: 1.0856 - val_accuracy: 0.6578\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.9909 - accuracy: 0.6949 - val_loss: 1.1346 - val_accuracy: 0.6514\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.9393 - accuracy: 0.7106 - val_loss: 1.0091 - val_accuracy: 0.6825\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.8919 - accuracy: 0.7263 - val_loss: 1.0077 - val_accuracy: 0.6801\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.8535 - accuracy: 0.7385 - val_loss: 0.9838 - val_accuracy: 0.6835\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.8178 - accuracy: 0.7489 - val_loss: 0.9360 - val_accuracy: 0.7036\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.7861 - accuracy: 0.7596 - val_loss: 0.8652 - val_accuracy: 0.7263\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.7565 - accuracy: 0.7692 - val_loss: 0.8242 - val_accuracy: 0.7390\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.7344 - accuracy: 0.7745 - val_loss: 0.9335 - val_accuracy: 0.7100\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.7218 - accuracy: 0.7779 - val_loss: 0.7722 - val_accuracy: 0.7675\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.7027 - accuracy: 0.7855 - val_loss: 0.7396 - val_accuracy: 0.7676\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.6795 - accuracy: 0.7894 - val_loss: 0.8229 - val_accuracy: 0.7369\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.6714 - accuracy: 0.7914 - val_loss: 0.7766 - val_accuracy: 0.7494\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6530 - accuracy: 0.7991 - val_loss: 0.6822 - val_accuracy: 0.7866\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.6405 - accuracy: 0.8036 - val_loss: 0.7709 - val_accuracy: 0.7525\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6262 - accuracy: 0.8070 - val_loss: 0.7817 - val_accuracy: 0.7498\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.6175 - accuracy: 0.8109 - val_loss: 0.7077 - val_accuracy: 0.7761\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.6051 - accuracy: 0.8149 - val_loss: 0.7797 - val_accuracy: 0.7492\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.5961 - accuracy: 0.8142 - val_loss: 0.6035 - val_accuracy: 0.8163\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.5904 - accuracy: 0.8185 - val_loss: 0.7774 - val_accuracy: 0.7560\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.5804 - accuracy: 0.8205 - val_loss: 0.6544 - val_accuracy: 0.7931\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.5614 - accuracy: 0.8276 - val_loss: 0.5878 - val_accuracy: 0.8172\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.5605 - accuracy: 0.8245 - val_loss: 0.6976 - val_accuracy: 0.7824\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.5631 - accuracy: 0.8245 - val_loss: 0.9368 - val_accuracy: 0.7079\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.5547 - accuracy: 0.8285 - val_loss: 0.7452 - val_accuracy: 0.7563\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.5394 - accuracy: 0.8337 - val_loss: 0.6456 - val_accuracy: 0.8011\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.5356 - accuracy: 0.8351 - val_loss: 0.6597 - val_accuracy: 0.7886\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.5275 - accuracy: 0.8360 - val_loss: 0.6691 - val_accuracy: 0.7865\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.5178 - accuracy: 0.8398 - val_loss: 0.6010 - val_accuracy: 0.8085\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.5178 - accuracy: 0.8406 - val_loss: 0.8093 - val_accuracy: 0.7538\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.5130 - accuracy: 0.8404 - val_loss: 0.6402 - val_accuracy: 0.8007\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.5032 - accuracy: 0.8435 - val_loss: 0.6135 - val_accuracy: 0.8061\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.4995 - accuracy: 0.8447 - val_loss: 0.6092 - val_accuracy: 0.8053\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.4850 - accuracy: 0.8501 - val_loss: 0.6457 - val_accuracy: 0.7974\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.4831 - accuracy: 0.8510 - val_loss: 0.5807 - val_accuracy: 0.8189\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.4819 - accuracy: 0.8510 - val_loss: 0.6737 - val_accuracy: 0.7914\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.4741 - accuracy: 0.8516 - val_loss: 0.6377 - val_accuracy: 0.7958\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.4744 - accuracy: 0.8517 - val_loss: 0.6233 - val_accuracy: 0.8004\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.4682 - accuracy: 0.8531 - val_loss: 0.5712 - val_accuracy: 0.8195\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.4672 - accuracy: 0.8545 - val_loss: 0.7744 - val_accuracy: 0.7594\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.4661 - accuracy: 0.8545 - val_loss: 0.5972 - val_accuracy: 0.8126\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.4552 - accuracy: 0.8593 - val_loss: 0.5962 - val_accuracy: 0.8127\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.4553 - accuracy: 0.8578 - val_loss: 0.5627 - val_accuracy: 0.8234\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.4415 - accuracy: 0.8637 - val_loss: 0.6064 - val_accuracy: 0.8057\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.4441 - accuracy: 0.8608 - val_loss: 0.6797 - val_accuracy: 0.7932\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.4336 - accuracy: 0.8646 - val_loss: 0.6013 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6012582634568214, 0.8140333294868469]"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0007668630001688477\n",
    "Lambda = 0.0009907294593495255\n",
    "hidden_nodes = 200\n",
    "batch_size = 1000\n",
    "epochs = 50\n",
    "\n",
    "adam = optimizers.Adam(lr = lr)\n",
    "\n",
    "adm_scrore_tuned = model_2_train_val(1, Lambda, hidden_nodes, batch_size, epochs, adam)\n",
    "adm_scrore_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c965MYeHCCaT"
   },
   "source": [
    "### **Evaluated the Test Dataset over the model having the best accuracy for train and validation data with minimum loss possible **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qVJDPFhG-OO7",
    "outputId": "fa1066ec-6bf0-4a92-c5ab-55e8cf2fd79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 13s 309us/step - loss: 1.8151 - accuracy: 0.4280 - val_loss: 2.2783 - val_accuracy: 0.2831\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 12s 296us/step - loss: 1.1553 - accuracy: 0.6384 - val_loss: 1.6567 - val_accuracy: 0.4693\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 12s 293us/step - loss: 0.9633 - accuracy: 0.6991 - val_loss: 1.4389 - val_accuracy: 0.5064\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 12s 293us/step - loss: 0.8671 - accuracy: 0.7310 - val_loss: 1.4658 - val_accuracy: 0.4971\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 12s 293us/step - loss: 0.7954 - accuracy: 0.7535 - val_loss: 1.4998 - val_accuracy: 0.5234\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 12s 294us/step - loss: 0.7551 - accuracy: 0.7651 - val_loss: 1.2061 - val_accuracy: 0.6025\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.6984 - accuracy: 0.7821 - val_loss: 0.8971 - val_accuracy: 0.7120\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.6491 - accuracy: 0.7993 - val_loss: 0.8339 - val_accuracy: 0.7290\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.6193 - accuracy: 0.8075 - val_loss: 1.0683 - val_accuracy: 0.6565\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.6014 - accuracy: 0.8157 - val_loss: 1.0129 - val_accuracy: 0.6988\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 13s 298us/step - loss: 0.5758 - accuracy: 0.8208 - val_loss: 1.1232 - val_accuracy: 0.6451\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.5579 - accuracy: 0.8270 - val_loss: 0.7298 - val_accuracy: 0.7618\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.5384 - accuracy: 0.8299 - val_loss: 0.8679 - val_accuracy: 0.7225\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.5227 - accuracy: 0.8357 - val_loss: 0.8164 - val_accuracy: 0.7343\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.5171 - accuracy: 0.8376 - val_loss: 0.8552 - val_accuracy: 0.7285\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.4929 - accuracy: 0.8457 - val_loss: 0.6150 - val_accuracy: 0.8095\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 15s 363us/step - loss: 0.4729 - accuracy: 0.8540 - val_loss: 0.8898 - val_accuracy: 0.7262\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.4714 - accuracy: 0.8518 - val_loss: 0.8786 - val_accuracy: 0.7121\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.4482 - accuracy: 0.8595 - val_loss: 0.7443 - val_accuracy: 0.7608\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.4490 - accuracy: 0.8607 - val_loss: 0.5676 - val_accuracy: 0.8307\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.4380 - accuracy: 0.8630 - val_loss: 0.6365 - val_accuracy: 0.7934\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.4232 - accuracy: 0.8652 - val_loss: 0.5762 - val_accuracy: 0.8190\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 0.4110 - accuracy: 0.8730 - val_loss: 0.6256 - val_accuracy: 0.8027\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.4050 - accuracy: 0.8710 - val_loss: 0.6012 - val_accuracy: 0.8146\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 12s 294us/step - loss: 0.3945 - accuracy: 0.8762 - val_loss: 0.5017 - val_accuracy: 0.8473\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.3878 - accuracy: 0.8771 - val_loss: 0.5389 - val_accuracy: 0.8385\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 12s 294us/step - loss: 0.3855 - accuracy: 0.8785 - val_loss: 0.8452 - val_accuracy: 0.7434\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 12s 293us/step - loss: 0.3726 - accuracy: 0.8811 - val_loss: 0.5740 - val_accuracy: 0.8206\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.3666 - accuracy: 0.8839 - val_loss: 0.7211 - val_accuracy: 0.7771\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.3531 - accuracy: 0.8887 - val_loss: 0.5906 - val_accuracy: 0.8162\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.3487 - accuracy: 0.8881 - val_loss: 0.4489 - val_accuracy: 0.8637\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.3419 - accuracy: 0.8926 - val_loss: 0.7148 - val_accuracy: 0.7795\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.3391 - accuracy: 0.8913 - val_loss: 0.4576 - val_accuracy: 0.8627\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.3295 - accuracy: 0.8960 - val_loss: 0.5753 - val_accuracy: 0.8162\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 12s 293us/step - loss: 0.3247 - accuracy: 0.8970 - val_loss: 0.5257 - val_accuracy: 0.8381\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 13s 300us/step - loss: 0.3145 - accuracy: 0.9000 - val_loss: 0.4281 - val_accuracy: 0.8703\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.3109 - accuracy: 0.9015 - val_loss: 1.2348 - val_accuracy: 0.5978\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 12s 293us/step - loss: 0.3116 - accuracy: 0.8999 - val_loss: 0.4510 - val_accuracy: 0.8677\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.2963 - accuracy: 0.9071 - val_loss: 0.5101 - val_accuracy: 0.8421\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 13s 301us/step - loss: 0.2992 - accuracy: 0.9044 - val_loss: 0.4132 - val_accuracy: 0.8779\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.2937 - accuracy: 0.9080 - val_loss: 0.4113 - val_accuracy: 0.8802\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.2856 - accuracy: 0.9100 - val_loss: 0.6159 - val_accuracy: 0.8130\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 12s 289us/step - loss: 0.2806 - accuracy: 0.9104 - val_loss: 0.5126 - val_accuracy: 0.8470\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.2726 - accuracy: 0.9128 - val_loss: 0.4311 - val_accuracy: 0.8718\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.2689 - accuracy: 0.9152 - val_loss: 0.3789 - val_accuracy: 0.8901\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.2676 - accuracy: 0.9146 - val_loss: 0.5256 - val_accuracy: 0.8401\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.2614 - accuracy: 0.9168 - val_loss: 0.5916 - val_accuracy: 0.8300\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 12s 292us/step - loss: 0.2649 - accuracy: 0.9157 - val_loss: 0.5928 - val_accuracy: 0.8173\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 12s 291us/step - loss: 0.2599 - accuracy: 0.9177 - val_loss: 0.3467 - val_accuracy: 0.9030\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 12s 295us/step - loss: 0.2482 - accuracy: 0.9214 - val_loss: 0.4525 - val_accuracy: 0.8673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6958537618451648, 0.8130555748939514]"
      ]
     },
     "execution_count": 135,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0007668630001688477\n",
    "Lambda = 0.0009907294593495255\n",
    "hidden_nodes = 512\n",
    "output_nodes = 10\n",
    "\n",
    "model_final = Sequential()\n",
    "\n",
    "model_final.add(Dense(hidden_nodes, input_shape = (1024, ), activation='relu'))\n",
    "model_final.add(BatchNormalization())  \n",
    "model_final.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "model_final.add(BatchNormalization())  \n",
    "model_final.add(Dropout(0.25))\n",
    "model_final.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "model_final.add(BatchNormalization()) \n",
    "model_final.add(Dropout(0.25))\n",
    "model_final.add(Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu'))\n",
    "model_final.add(Dropout(0.2))\n",
    "model_final.add(Dense(output_nodes, kernel_initializer='he_normal', activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))  \n",
    "\n",
    "# Compile model\n",
    "opt = optimizers.Adam(lr = lr)\n",
    "model_final.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_final.fit(X_train, y_train,validation_data=(X_val,y_val), batch_size = 200, epochs = 50, verbose = 1)\n",
    "final_scores=model_final.evaluate(X_test,y_test,verbose=0)\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NbSgqGJGCesA"
   },
   "source": [
    "\n",
    "\n",
    "*   Train Accuracy : 0.9214 , Train Loss : 0.2482\n",
    "*   Validation Accuracy : 0.8673 , Validation Loss : 0.4525\n",
    "*   Test Accuracy : 0.81305 , Test Loss : 0.6958\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
